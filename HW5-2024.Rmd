---
title: "HW5"
author: "Steven He"
date: "2024-02-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE ,echo = FALSE)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(mosaic)
library(stringr)
library(kableExtra)
```

## Question 1

```{r }
SEC_sim <- do(100000)*nflip(n = 2021, prob = .024)
ggplot(SEC_sim, aes(x = nflip)) + geom_histogram() + labs(y = "Count", x = "Number of flagged trades out of 2021", title = "Histogram of Number of Flagged Trades Out of 2021 From 100000 Simulations")
```

Null hypothesis: Given that the probability of 2.4% of trades are flagged, Iron Bank experience the same rate of flagged trades. 

Test Statistic: 2.4% of trades are flagged

P-value: `r sum(SEC_sim >= 70)/100000`

Conclusion: Given how small the p-value is, being much smaller than .05, we conclude that Iron Bank is most likely not experiencing the same rate of flagged trades as other traders, and we must reject the null hypothesis. 

## Question 2

```{r pressure, echo=FALSE}
gorbit_sim <- do(100000)*nflip(n = 50, prob = .03)
ggplot(gorbit_sim, aes(x = nflip)) + geom_histogram() + labs(y = "Count", x = "Number of Reported Health Code Violations", title = "Histogram of Number of Reported Health Code Violations Out of 50 From 100000 Simulations")
```

Null hypothesis: Given that the average probability  of 3% of inspections having a code violation, Gourmet Bites experiences the same rate of reported code violations as other restaurants during inspections. 

Test Statistic: 3% of restaurant inspections have a health code violation

P-value: `r sum(gorbit_sim >= 8)/100000`

Conclusion: Given how small the p-value is, being much smaller than .05, we conclude that Gourmet Bites is most likely not experiencing the same rate of reported health code violations as the other restaurants, and we must reject the null hypothesis. 

## Question 3 

```{r}
#Part A
blines <- readLines("brown_sentences.txt")
letter <- read.csv("letter_frequencies.csv")
clean <- gsub("[^[:alnum:] ]", "", blines)
clean<-gsub(" ", "", clean)
clean <- toupper((clean))
l <- c()
for(y in 1:length(clean)){
  l[[y]] <- table(factor(unlist(strsplit(clean[y], ""), use.names=FALSE), levels=letter$Letter))
}
counts <- as.data.frame(do.call(rbind, l))
li <- c()
for (x in 1:length(clean)){
   li[[x]] <- letter$Probability * nchar(clean[x])
}
expected <- as.data.frame(do.call(rbind, li))
chi <- rowSums((counts - expected)^2/ expected)

#Part B

sentences <- c(
  "She opened the book and started to read the first chapter, eagerly anticipating what might come next.",
  "Despite the heavy rain, they decided to go for a long walk in the park, crossing the main avenue by the fountain in the center.",
  "The museum’s new exhibit features ancient artifacts from various civilizations around the world.",
  "He carefully examined the document, looking for any clues that might help solve the mystery.",
  "The students gathered in the auditorium to listen to the guest speaker’s inspiring lecture.",
  "Feeling vexed after an arduous and zany day at work, she hoped for a peaceful and quiet evening at home, cozying up after a quick dinner with some TV, or maybe a book on her upcoming visit to Auckland.",
  "The chef demonstrated how to prepare a delicious meal using only locally sourced ingredients, focusing mainly on some excellent dinner recipes from Spain.",
  "They watched the sunset from the hilltop, marveling at the beautiful array of colors in the sky.",
  "The committee reviewed the proposal and provided many points of useful feedback to improve the project’s effectiveness.",
  "Despite the challenges faced during the project, the team worked tirelessly to ensure its successful completion, resulting in a product that exceeded everyone’s expectations."
)
Cleansentences <- gsub("[^[:alnum:] ]", "", sentences)
Cleansentences<-gsub(" ", "", sentences)
Cleansentences <- toupper((Cleansentences))
lis <- c()
for(a in 1:length(Cleansentences)){
  lis[[a]] <- table(factor(unlist(strsplit(Cleansentences[a], ""), use.names=FALSE), levels=letter$Letter))
}
countsText <- as.data.frame(do.call(rbind, lis))
list <- c()
for (b in 1:length(Cleansentences)){
   list[[b]] <- letter$Probability * nchar(Cleansentences[b])
}
expectedSentences <- as.data.frame(do.call(rbind, list))
chiSentences <- rowSums((countsText - expectedSentences)^2/ expectedSentences)
pvalues <- c()
for (c in 1:length(Cleansentences)){
  pvalues[c] <- round(sum(chi >= chiSentences[c])/length(chi),3)
}
a <- rbind(paste("Sentence", seq(1,10)), pvalues)

kable(a) %>%
  kable_styling(bootstrap_options = "striped", font_size = 15)
```

Sentence 6 is most likely produced by an LLM, due to it having the smallest p-value by a significant amount, meaning it differed the most from the given letter frequencies out of all the sentences. 